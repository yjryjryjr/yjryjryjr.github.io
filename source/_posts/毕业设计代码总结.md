---
title: 毕业设计代码总结
date: 2024-05-24 20:14 
tags:
---
<head>
  <meta name="referrer" content="no-referrer" />
</head>

## 自序

​	这次毕业设计时间之紧，任务之重，实在给我带来了很大压力，好在最后还是顺利完成了毕设。因为我的毕设做的是算法研究和实践，没有前人做过一样的东西，在这之中颇有品尝到些许科研的苦乐之味，有感悟是：科研像爬山，山路错综复杂，更没有什么指引，攀登者的最终目标就是登顶。这过程中大部分攀登者兜兜转转，耗尽心血，郁郁不得志；更有攀登者误入歧途，走火入魔，死在路上；只有极少数的勇敢智慧兼备之人堵上自己的全部，最终能够登上山顶，一窥山顶的瑰丽。当然并不是只有登顶才是成功，其他都是失败，科研之山攀登的乐趣也并不是只在登顶，有人乐在攀登的过程，有人乐在沿途的风景，或者有的人目标只是半山腰的某个宝藏，这些都于人格于格局于心态。

​	科研之苦自不用说，辗转反侧，夜不能寐，对人的折磨是极大的，因此不提倡破釜沉舟。拥有下山的智慧才是一个科研人对自己应有的救赎。

## 前言

本次毕设涉及技术有Python基础语法，PyTorch，PyTorch-Geometric（PyG），GraphQL等

## Python基础语法

Python的main函数写法：

```python
if __name__ == '__main__':
    pass
```

字符串占位格式化：

```py
string1 = "%s love %s"
formatted_string1 = string1 % ("I", "you")
print(formatted_string1) # I love you
```

分隔字符串

```py
s = "hello/world"
parts = s.split('/')
s1 = parts[0] # hello
s2 = parts[1] # world
```

pandas库新建csv文件：

```python
df = pd.DataFrame(columns=['id', 'repo']) # 新建列表头
df.to_csv('file.csv', index=False) # index=False代表无需行号
```

pandas库加入新的一行：

```py
new_row = {'id' : global_id, 'repo' : repo}
new_df = pd.DataFrame([new_row])
df = pd.concat([df, new_df], ignore_index=True)
```

pandas库按键值查找某行的某个元素：

```python
"""
假设csv文件：
name,age,city
Alice,25,New York
Bob,30,Los Angeles
...
查找Alice所在城市
"""
city = df.set_index('name').to_dict(orient='index')
```

pandas库读取csv文件并遍历每一行：

```python
df = pd.read_csv('file.csv')
for index, row in df.iterrows():
    """
    假设csv文件：
    r1,r2
    1,2
    2,1
    ....
    """
    print(row['r1'])
    print(row['r2'])
```

pandas库将csv的一列转为一个列表：

```python
df = pd.read_csv('file.csv')
r1 = df['r1'].to_list()
r2 = df['r2'].to_list()
```

json库读取json文件：

```py
with open('file.json') as json_data:
    data = json.load(json_data)
```



## PyTorch和PyG

将一个Python普通数据转换成torch的张量：

```python
data = torch.tensor(data)
```

划分数据集并使用DataLoader读取：

```python
total_size = len(dataset)
train_size = int(0.6 * total_size)
test_size = total_size - train_size
train_dataset, test_dataset = random_split(dataset, [train_size, test_size]) # 打乱分隔
train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)
```

将数据放到GPU/CPU上：

```python
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = My_Model().to(device)
```

自定义神经网络模型：

```python
import torch.nn.functional as F
class My_Model(torch.nn.Module): # My_Model继承自torch.nn.Module
    def __init__(self, in_channels, hidden_channels, out_channels, num_layers):
        
        # 初始化父类
        super().__init__() 
        
        # 自定义变量
        self.自定义变量 = 某个模块/变量
        self.conv1 = SAGEConv(in_channels, hidden_channels) # 逐个定义神经网络层
        self.conv2 = SAGEConv(hidden_channels, hidden_channels)
        self.conv3 = SAGEConv(hidden_channels, out_channels)
        
        self.convs = torch.nn.ModuleList() # 定义神经网络列表，改变层数则修改num_layers
        self.num_layers = num_layers
        self.convs.append(SAGEConv(in_channels, hidden_channels))
        for _ in range(num_layers - 2):
            self.convs.append(SAGEConv(hidden_channels, hidden_channels))
        self.convs.append(SAGEConv(hidden_channels, out_channels))
        
    def forward(self, x, edge_index, batch):
        # 串联神经网络层，中间加入激活函数relu防止过拟合
        x = self.conv1(x, edge_index)
        x = x.relu()
        x = self.conv2(x, edge_index)
        x = x.relu()
        x = self.conv3(x, edge_index)
        
        # dropout层防止过拟合
        x = F.dropout(x, p=0.5, training=self.training)

        return x
```

优化器和损失函数：

```python
# Adam优化器
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

# 交叉熵损失函数
criterion = torch.nn.CrossEntropyLoss()
```

训练模型：

```python
def train(train_loader):
    # 将模型调到train()模式
    model.train()
    
    for data in train_loader: # 在训练数据集上分batch迭代
        # 进行一次前向传播
        out = model(data.x, data.edge_index, data.batch)
        
        # 计算损失函数
        loss = criterion(out, data.y)
        
        # 反向传播计算梯度
        loss.backward()
        
        # 根据梯度使用优化器优化模型参数
        optimizer.step()
        
        # 清除模型梯度
        optimizer.zero_grad()
```

测试模型：

```python
def test(test_loader):
    # 将模型调到test()模式
    model.eval()
    
    for data in test_loader: # 在测试数据集上分batch迭代
        # 进行一次前向传播
        out = model(data.x, data.edge_index, data.batch)
        
        # 如果是分类任务
        pred = out.argmax(dim=1) # 使用概率最大的分类
        correct += int((pred == data.y).sum()) # 与真实值做比较
        
    return correct / len(test_loader.dataset) # 计算预测准确率并返回
        
```

训练主函数：

```python
for epoch in range(1000):
    train() # 进行一次训练
    train_acc = test(train_loader) # 得出训练准确率
    test_acc = test(test_loader) # 得出测试准确率
    print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')
    
```



## GraphQL

```python
"""
查询仓库的依赖
"""
query{
  repository(owner:"%s", name:"%s") {
    dependencyGraphManifests{
      edges {
        node {
          dependencies{
            nodes {
              repository{
                owner{
                  login
                }
                name
              }
            }
          }
        }
      }
    }
  }
}
```

```python
"""
查询仓库的特征
"""
query{
  repository(owner:"%s", name:"%s") {
    owner{
      login
    }
    name
    forkCount
    stargazerCount
    pullRequests(states: MERGED) {
      totalCount
    }
    releases {
      totalCount
    }
  }
}
```



## NetworkX

```python
# 绘制展示社交网络
G = to_networkx(data, to_undirected=True) # data是PyG的格式的数据集
nx.draw(G)
```

## 后记

本次毕业设计对Python脚本进一步熟悉了一下，尤其是文件处理和爬虫的知识，其次是对使用PyTorch和PyG的神经网络的搭建和训练有了基础的认识，最后还对GraphQL，Gephi绘图以及论文撰写和参考文献引用等知识有了更进一步了解。
